{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps \n",
    "#1: import all the important libraries\n",
    "#2: extract important pairs from sklearn to work with \n",
    "#3: load the data from json \n",
    "#4: process and clean the data using certain regex rules\n",
    "#5: define the tfidf model, feed all the data in it\n",
    "#6: use the tfidf vectorizer tool to work with the data\n",
    "#7: classify sentences using the feature weights\n",
    "#8: use a cosine similarity matrix to calculate and predict the next words using the feature weights\n",
    "#9: create a user interface to get user inputs\n",
    "#based on all of the above steps, The Autocomplete will recognize the closest sentenses and rank 3 final proposals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the required libraries\n",
    "import json\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use of sklearn and extracting important pairs to work with \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaidng json data \n",
    "DATA_DIR = './'\n",
    "\n",
    "def load_df(json_path='name.json'):\n",
    "    \n",
    "    df = pd.read_json(DATA_DIR+json_path)\n",
    "    \n",
    "    for column in ['Issues']:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [str(column+\"_\"+subcolumn) for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame([dict(y, index=i) for i, x in enumerate(df['Issues_Messages'].values.tolist()) for y in x])\n",
    "    \n",
    "    print(df.shape)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process the data \n",
    "def splitDataFrameList(df,target_column,separator):\n",
    "    \n",
    "    \n",
    "    def split_text(line, separator):\n",
    "        splited_line =  [e+d for e in line.split(separator) if e]\n",
    "        return splited_line\n",
    "    \n",
    "    def splitListToRows(row,row_accumulator,target_column,separator):\n",
    "        split_row = row[target_column].split(separator)\n",
    "        for s in split_row:\n",
    "            new_row = row.to_dict()\n",
    "            new_row[target_column] = s\n",
    "            row_accumulator.append(new_row)\n",
    "    new_rows = []\n",
    "    df.apply(splitListToRows,axis=1,args = (new_rows,target_column,separator))\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning your data using few regex rules\n",
    "class Autocompleter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def import_json(self, json_filename):\n",
    "        print(\"load json file...\")\n",
    "        df = load_df(json_filename)\n",
    "        return df\n",
    "        \n",
    "    def process_data(self, new_df):\n",
    "\n",
    "        print(\"select representative threads...\")\n",
    "        new_df = new_df[new_df.IsFromCustomer==False]\n",
    "        \n",
    "        print(\"split sentenses on punctuation...\")\n",
    "        for sep in ['. ',', ','? ', '! ', '; ']:\n",
    "            new_df = splitDataFrameList(new_df, 'Text', sep)\n",
    "            \n",
    "        print(\"Text Cleaning using simple regex...\")\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: \" \".join(x.split()))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.strip(\".\"))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: \" \".join(x.split()))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' i ',' I '))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' ?','?'))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' !','!'))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' .','.'))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.replace('OK','Ok'))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x[0].upper()+x[1:])\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x+\"?\" if re.search(r'^(Wh|How).+([^?])$',x) else x)\n",
    "        \n",
    "        print(\"calculate nb words of sentenses...\")\n",
    "        new_df['nb_words'] = new_df['Text'].apply(lambda x: len(str(x).split(' ')))\n",
    "        new_df = new_df[new_df['nb_words']>2]\n",
    "        \n",
    "        print(\"count occurence of sentenses...\")\n",
    "        new_df['Counts'] = new_df.groupby(['Text'])['Text'].transform('count')\n",
    "        \n",
    "        print(\"remove duplicates (keep last)...\")\n",
    "        new_df = new_df.drop_duplicates(subset=['Text'], keep='last')\n",
    "        \n",
    "        new_df = new_df.reset_index(drop=True)\n",
    "        print(new_df.shape)  \n",
    "        \n",
    "        return new_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tfidf parameter in order to count/vectorize the description vector and then normalize it.\n",
    "def calc_matrice(self, df):\n",
    "        # define tfidf parameter in order to count/vectorize the description vector and then normalize it.\n",
    "        model_tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 5), min_df=0)\n",
    "        tfidf_matrice = model_tf.fit_transform(df['Text'])\n",
    "        print(\"tfidf_matrice \", tfidf_matrice.shape)\n",
    "        return model_tf, tfidf_matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the similarity matrix and use it to predict the next words\n",
    "def generate_completions(self, prefix_string, data, model_tf, tfidf_matrice):\n",
    "        \n",
    "        prefix_string = str(prefix_string)\n",
    "        new_df = data.reset_index(drop=True)\n",
    "        weights = new_df['Counts'].apply(lambda x: 1+ np.log1p(x)).values\n",
    "\n",
    "        # tranform the string using the tfidf model\n",
    "        tfidf_matrice_spelling = model_tf.transform([prefix_string])\n",
    "        # calculate cosine_matrix\n",
    "        cosine_similarite = linear_kernel(tfidf_matrice, tfidf_matrice_spelling)\n",
    "        \n",
    "        #sort by order of similarity from 1 to 0:\n",
    "        similarity_scores = list(enumerate(cosine_similarite))\n",
    "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        similarity_scores = similarity_scores[0:10]\n",
    "\n",
    "        similarity_scores = [i for i in similarity_scores]\n",
    "        similarity_indices = [i[0] for i in similarity_scores]\n",
    "\n",
    "        #add weight to the potential results that had high frequency in orig data\n",
    "        for i in range(len(similarity_scores)):\n",
    "            similarity_scores[i][1][0]=similarity_scores[i][1][0]*weights[similarity_indices][i]\n",
    "\n",
    "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        similarity_scores = similarity_scores[0:3]\n",
    "        similarity_indices_w = [i[0] for i in similarity_scores]\n",
    "        \n",
    "        return new_df.loc[similarity_indices_w]['Text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autocompleter \n",
    "autocompl = autocompleter.Autocompleter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load json file...\n",
      "(22264, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((22264, 3), Index(['IsFromCustomer', 'Text', 'index'], dtype='object'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying the corpus\n",
    "df = autocompl.import_json(\"sample_conversations.json\")\n",
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsFromCustomer</th>\n",
       "      <th>Text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Hi! I placed an order on your website and I ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>I think I used my email address to log in.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>My battery exploded!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>It's on fire, it's melting the carpet!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>What should I do!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>I'm interested in upgrading my plan.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Can you tell me a bit about Prime?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>My friend has it, and it seems like a great deal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>Hello</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>Hello Werner how may I help you today?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsFromCustomer                                               Text  index\n",
       "0            True  Hi! I placed an order on your website and I ca...      0\n",
       "1            True         I think I used my email address to log in.      0\n",
       "2            True                               My battery exploded!      1\n",
       "3            True             It's on fire, it's melting the carpet!      1\n",
       "4            True                                  What should I do!      1\n",
       "5            True               I'm interested in upgrading my plan.      2\n",
       "6            True                 Can you tell me a bit about Prime?      2\n",
       "7            True   My friend has it, and it seems like a great deal      2\n",
       "8            True                                              Hello      3\n",
       "9           False             Hello Werner how may I help you today?      3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first 10 values of the corpus after cleaning and normalising stuff \n",
    "df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select representative threads...\n",
      "split sentenses on punctuation...\n",
      "Text Cleaning using simple regex...\n",
      "calculate nb words of sentenses...\n",
      "count occurence of sentenses...\n",
      "remove duplicates (keep last)...\n",
      "(8601, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8601, 5),\n",
       " Index(['IsFromCustomer', 'Text', 'index', 'nb_words', 'Counts'], dtype='object'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = autocompl.process_data(df)\n",
    "new_df.shape, new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_matrice  (8601, 99656)\n"
     ]
    }
   ],
   "source": [
    "model_tf, tfidf_matrice = autocompl.calc_matrice(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let me\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Let me investigate', 'Let me assist you', 'Let me look']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a user input \n",
    "#applying all the required steps\n",
    "#using the prefix variable to take the input \n",
    "prefix = input()\n",
    "autocompl.generate_completions(prefix, new_df, model_tf,tfidf_matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what can \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What can I help you with today?',\n",
       " 'Let me see what I can do',\n",
       " 'I will see what I can do']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = input()\n",
    "autocompl.generate_completions(prefix, new_df, model_tf,tfidf_matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you need\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Do you need any more help?',\n",
       " 'Do you need assistance in doing this?',\n",
       " 'Which do you prefer?']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = input()\n",
    "autocompl.generate_completions(prefix, new_df, model_tf,tfidf_matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
